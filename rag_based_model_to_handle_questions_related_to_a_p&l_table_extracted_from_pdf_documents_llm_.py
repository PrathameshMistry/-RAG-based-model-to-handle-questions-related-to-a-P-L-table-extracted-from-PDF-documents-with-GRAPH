# -*- coding: utf-8 -*-
"""RAG-based model to handle questions related to a P&L table extracted from  PDF documents. LLM .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tgR1_3OM5xFC6YVtSNJuacOUfCR2SeR5
"""

# Import required libraries
!pip install pypdf langchain sentence_transformers faiss-cpu openai pinecone-client
# First install required libraries
!pip install PyPDF2
!pip install pandas

# Install required packages
!pip install -q langchain-community langchain chromadb PyPDF2 pandas tiktoken sentence-transformers huggingface_hub python-dotenv matplotlib seaborn

import os
import logging
import warnings
warnings.filterwarnings('ignore')
import PyPDF2
import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import HuggingFaceHub
from transformers import pipeline
from google.colab import files

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AdvancedFinancialQASystem:
    def __init__(
        self,
        hf_token: str,
        model_name: str = "mistralai/Mixtral-8x7B-Instruct-v0.1",
        embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2",
        persist_directory: str = "./financial_qa_db",
        max_retries: int = 3
    ):
        """Initialize the advanced financial QA system with enhanced features."""
        self.hf_token = hf_token
        self.max_retries = max_retries

        # Configure environment
        os.environ["HUGGINGFACEHUB_API_TOKEN"] = hf_token
        load_dotenv()

        # Initialize components
        self._init_llm(model_name)
        self._init_embeddings(embedding_model)
        self._init_vector_store(persist_directory)
        self._init_sentiment_analyzer()
        self._init_memory()

        # Financial data storage
        self.df: Optional[pd.DataFrame] = None
        self.metrics_history: Dict[str, List] = {}

    def _init_llm(self, model_name: str):
        """Initialize language model with advanced configuration."""
        self.llm = HuggingFaceHub(
            repo_id=model_name,
            huggingfacehub_api_token=self.hf_token,
            model_kwargs={
                "temperature": 0.3,
                "max_new_tokens": 2048,
                "top_p": 0.95,
                "repetition_penalty": 1.15
            }
        )

    def _init_embeddings(self, embedding_model: str):
        """Initialize embeddings with error handling."""
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name=embedding_model,
                model_kwargs={'device': 'cpu'}
            )
        except Exception as e:
            logger.error(f"Embedding initialization failed: {str(e)}")
            raise

    def _init_vector_store(self, persist_directory: str):
        """Initialize vector store with retry logic."""
        self.vector_store = None
        self.persist_directory = persist_directory
        if os.path.exists(persist_directory):
            try:
                self.vector_store = Chroma(
                    persist_directory=persist_directory,
                    embedding_function=self.embeddings
                )
                logger.info("Loaded existing vector store")
            except Exception as e:
                logger.warning(f"Vector store load failed: {str(e)}")

    def _init_sentiment_analyzer(self):
        """Initialize financial-specific sentiment analysis."""
        self.sentiment_analyzer = pipeline(
            "text-classification",
            model="mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis",
            top_k=1
        )

    def _init_memory(self):
        """Initialize conversation memory with enhanced capacity."""
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            input_key="question",
            output_key="answer",
            max_token_limit=4000
        )

    def read_pdf(self, file_path: str) -> Optional[str]:
        """Advanced PDF processing with text normalization and validation."""
        logger.info(f"Processing PDF: {file_path}")
        try:
            with open(file_path, 'rb') as pdf_file:
                pdf_reader = PyPDF2.PdfReader(pdf_file)
                text = "\n".join([
                    self._normalize_text(page.extract_text())
                    for page in pdf_reader.pages
                    if len(page.extract_text()) > 50  # Skip empty pages
                ])

            if len(text) < 1000:
                raise ValueError("PDF appears to be empty or image-based")

            return self._process_text(text)

        except Exception as e:
            logger.error(f"PDF processing failed: {str(e)}")
            return None

    def _normalize_text(self, text: str) -> str:
        """Normalize text for consistent processing."""
        # Remove non-ASCII characters and normalize whitespace
        text = re.sub(r'[^\x00-\x7F]+', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def _process_text(self, text: str) -> str:
        """Process and split text with adaptive chunking."""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            is_separator_regex=False
        )
        texts = text_splitter.split_text(text)

        if self.vector_store is None:
            self.vector_store = Chroma.from_texts(
                texts=texts,
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
        else:
            self.vector_store.add_texts(texts)

        return text

    def extract_financial_data(self, text: str) -> pd.DataFrame:
        """Advanced financial data extraction with multiple metrics."""
        patterns = {
            'Revenue': r'(Revenue|Sales).*?(?:FY2024|2024)[\D]*([\d,]+).*?(?:FY2023|2023)[\D]*([\d,]+)',
            'Net Profit': r'(Net Profit|Net Income).*?(?:FY2024|2024)[\D]*([\d,]+).*?(?:FY2023|2023)[\D]*([\d,]+)',
            'EBITDA': r'(EBITDA).*?(?:FY2024|2024)[\D]*([\d,]+).*?(?:FY2023|2023)[\D]*([\d,]+)',
            'Gross Margin': r'(Gross Margin).*?(?:FY2024|2024)[\D]*([\d,]+).*?(?:FY2023|2023)[\D]*([\d,]+)'
        }

        data = {'Metric': [], 'FY2024': [], 'FY2023': []}

        for metric, pattern in patterns.items():
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data['Metric'].append(metric)
                data['FY2024'].append(self._clean_number(match.group(2)))
                data['FY2023'].append(self._clean_number(match.group(3)))

        self.df = pd.DataFrame(data).drop_duplicates().reset_index(drop=True)
        self._validate_financial_data()
        return self.df

    def _clean_number(self, value: str) -> float:
        """Convert financial numbers to standardized format."""
        try:
            return float(re.sub(r'[^\d.]', '', value.replace(',', '')))
        except:
            return 0.0

    def _validate_financial_data(self):
        """Data validation checks."""
        if self.df is not None:
            if self.df.empty:
                logger.warning("No financial metrics extracted")
            else:
                logger.info(f"Extracted {len(self.df)} financial metrics")

    def generate_response(self, question: str) -> Dict:
        """Generate response with retry logic and enhanced context."""
        if not self.vector_store:
            return {"error": "Document database not initialized"}

        for attempt in range(self.max_retries):
            try:
                qa_chain = ConversationalRetrievalChain.from_llm(
                    llm=self.llm,
                    retriever=self.vector_store.as_retriever(
                        search_type="mmr",
                        search_kwargs={"k": 5, "fetch_k": 10}
                    ),
                    memory=self.memory,
                    return_source_documents=True,
                    verbose=True
                )

                response = qa_chain({"question": question})
                answer = response["answer"].strip()

                # Enhanced post-processing
                answer = self._post_process_answer(answer)
                sentiment = self._analyze_sentiment(answer)

                return {
                    "answer": answer,
                    "sentiment": sentiment,
                    "sources": [doc.metadata for doc in response["source_documents"][:3]],
                    "context_score": response.get("context_score", 0.0)
                }

            except Exception as e:
                logger.warning(f"Attempt {attempt+1} failed: {str(e)}")
                if attempt == self.max_retries - 1:
                    return {"error": f"Failed after {self.max_retries} attempts: {str(e)}"}

    def _post_process_answer(self, answer: str) -> str:
        """Clean and format the generated answer."""
        # Remove redundant phrases
        answer = re.sub(r'\b(However|Moreover|Additionally),?', '', answer)
        # Fix number formatting
        answer = re.sub(r'(\d),(\d)', r'\1,\2', answer)
        # Remove empty parentheses
        answer = re.sub(r'\(\s*\)', '', answer)
        return answer.strip()

    def _analyze_sentiment(self, text: str) -> Dict:
        """Analyze sentiment with fallback mechanism."""
        try:
            result = self.sentiment_analyzer(text[:512])[0][0]
            return {
                "label": result['label'],
                "score": round(float(result['score']), 3)
            }
        except Exception as e:
            logger.error(f"Sentiment analysis failed: {str(e)}")
            return {"label": "NEUTRAL", "score": 0.0}

    def visualize_data(self, metric: str):
        """Visualize financial data using matplotlib/seaborn."""
        if self.df is None or self.df.empty:
            return "No financial data available for visualization."

        if metric not in self.df['Metric'].values:
            return f"Metric '{metric}' not found in the data."

        plt.figure(figsize=(10, 6))
        sns.barplot(data=self.df[self.df['Metric'] == metric], x='Metric', y='FY2024', color='blue', label='FY2024')
        sns.barplot(data=self.df[self.df['Metric'] == metric], x='Metric', y='FY2023', color='orange', label='FY2023')
        plt.title(f"{metric} Comparison (FY2023 vs FY2024)")
        plt.xlabel('Metric')
        plt.ylabel('Value (in millions)')
        plt.legend()
        plt.show()

    def visualize_net_income_vs_operating_expenses(self):
        """Visualize net income vs operating expenses for Q1 2024."""
        if self.df is None or self.df.empty:
            return "No financial data available for visualization."

        # Example data for Q1 2024
        data = {
            'Category': ['Net Income', 'Operating Expenses'],
            'Amount': [26248, 14510]  # Example values in Crores
        }
        df = pd.DataFrame(data)

        plt.figure(figsize=(10, 6))
        sns.barplot(data=df, x='Category', y='Amount', palette=['blue', 'orange'])
        plt.title('Net Income vs Operating Expenses for Q1 2024')
        plt.xlabel('Category')
        plt.ylabel('Amount (in Crores)')
        plt.show()

def main():
    """Main execution flow with improved user interaction."""
    # Replace "YOUR_HUGGINGFACE_API_TOKEN" with your actual token
    hf_token = "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"

    try:
        qa_system = AdvancedFinancialQASystem(
            hf_token=hf_token,
            model_name="mistralai/Mixtral-8x7B-Instruct-v0.1"
        )

        print("📄 Upload a financial PDF document (e.g., annual report)")
        uploaded = files.upload()
        file_name = next(iter(uploaded))

        print("\n🔍 Analyzing document...")
        text = qa_system.read_pdf(file_name)

        if text:
            print("\n📊 Extracting financial metrics...")
            df = qa_system.extract_financial_data(text)
            print("\n✅ Key Financial Metrics:")
            print(df.to_markdown(index=False, tablefmt="grid"))

            while True:
                try:
                    user_question = input("\n❓ Your question (or 'exit' to quit): ")
                    if user_question.lower() in ['exit', 'quit']:
                        break

                    response = qa_system.generate_response(user_question)

                    if "error" in response:
                        print(f"⚠️ Error: {response['error']}")
                    else:
                        print(f"\n📝 Answer: {response['answer']}")
                        print(f"🎭 Sentiment: {response['sentiment']['label']} (confidence: {response['sentiment']['score']:.2f})")
                        print("🔗 Sources:")
                        for source in response['sources']:
                            print(f" - Page {source.get('page', 'N/A')}: {source.get('source', 'Unknown')}")

                        # Visualize relevant data
                        for metric in df['Metric']:
                            if metric.lower() in user_question.lower():
                                qa_system.visualize_data(metric)
                                break

                        # Visualize net income vs operating expenses for Q1 2024
                        if 'net income' in user_question.lower() and 'operating expenses' in user_question.lower():
                            qa_system.visualize_net_income_vs_operating_expenses()

                except KeyboardInterrupt:
                    print("\nOperation cancelled by user")
                    break

    except Exception as e:
        print(f"🚨 Critical error: {str(e)}")
        logger.exception("System failure:")

if __name__ == "__main__":
    main()

